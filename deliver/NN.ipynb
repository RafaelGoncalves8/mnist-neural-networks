{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.random.seed = 42\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True,\n",
    "                                transform=None)\n",
    "\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True,\n",
    "                               transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ../data\n",
      "    Transforms (if any): None\n",
      "    Target Transforms (if any): None\n",
      "\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Split: test\n",
      "    Root Location: ../data\n",
      "    Transforms (if any): None\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "print(mnist_trainset)\n",
    "print('')\n",
    "print(mnist_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset.data[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_len = mnist_trainset.data[0].size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(1)\n",
    "for i, img in enumerate(mnist_trainset.data[0:5]):\n",
    "    ax = fig.add_subplot(1,5,i+1)\n",
    "    ax.set_axis_off()\n",
    "    ax = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net architecture and train/test routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"MLP with 3 ReLU hidden layers and 1 softmax output layer\"\"\"\n",
    "    \n",
    "    def __init__(self, H, C):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(size_len*size_len, H)\n",
    "        self.fc2 = nn.Linear(H, H)\n",
    "        self.fc3 = nn.Linear(H, H)\n",
    "        self.fc4 = nn.Linear(H, C)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, size_len*size_len)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.softmax(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x_train, y_train, optimizer, criterion, epoch, disp=''):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model(x_train)\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if disp=='print':\n",
    "        print(\"Train Epoch: {}\\tLoss: {:.6f}\".format(epoch, loss.item()))\n",
    "    elif disp=='graph':\n",
    "        pass\n",
    "    \n",
    "    return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x_test, y_test, criterion, disp=''):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(x_test)\n",
    "        test_loss = criterion(output, y_test)\n",
    "\n",
    "    if disp=='print':\n",
    "        print(\"\\nTest set: Average loss: {:.4f}\\n\".format(test_loss))\n",
    "    elif disp=='graph':\n",
    "        pass\n",
    "        \n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist_trainset.data.float()\n",
    "y_train = mnist_trainset.targets\n",
    "\n",
    "X_test = mnist_testset.data.float()\n",
    "y_test = mnist_testset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net(100, 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "gamma = 10\n",
    "max_epoch = 100\n",
    "optimizer = optim.SGD(model.parameters(), lr=alpha)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\tLoss: 5.761347\n",
      "Train Epoch: 1\tLoss: 6.645049\n",
      "Train Epoch: 2\tLoss: 6.426782\n",
      "Train Epoch: 3\tLoss: 4.026203\n",
      "Train Epoch: 4\tLoss: 2.825845\n",
      "Train Epoch: 5\tLoss: 2.278574\n",
      "Train Epoch: 6\tLoss: 2.052420\n",
      "Train Epoch: 7\tLoss: 1.910081\n",
      "Train Epoch: 8\tLoss: 1.764348\n",
      "Train Epoch: 9\tLoss: 1.611848\n",
      "Train Epoch: 10\tLoss: 1.460411\n",
      "Train Epoch: 11\tLoss: 1.321166\n",
      "Train Epoch: 12\tLoss: 1.198248\n",
      "Train Epoch: 13\tLoss: 1.095159\n",
      "Train Epoch: 14\tLoss: 1.019107\n",
      "Train Epoch: 15\tLoss: 1.003167\n",
      "Train Epoch: 16\tLoss: 1.137683\n",
      "Train Epoch: 17\tLoss: 1.560563\n",
      "Train Epoch: 18\tLoss: 1.233567\n",
      "Train Epoch: 19\tLoss: 0.946835\n",
      "Train Epoch: 20\tLoss: 0.825545\n",
      "Train Epoch: 21\tLoss: 0.757117\n",
      "Train Epoch: 22\tLoss: 0.733004\n",
      "Train Epoch: 23\tLoss: 0.743758\n",
      "Train Epoch: 24\tLoss: 0.892473\n",
      "Train Epoch: 25\tLoss: 1.470630\n",
      "Train Epoch: 26\tLoss: 1.518587\n",
      "Train Epoch: 27\tLoss: 1.058077\n",
      "Train Epoch: 28\tLoss: 0.699672\n",
      "Train Epoch: 29\tLoss: 0.622593\n",
      "Train Epoch: 30\tLoss: 0.585923\n",
      "Train Epoch: 31\tLoss: 0.560734\n",
      "Train Epoch: 32\tLoss: 0.541747\n",
      "Train Epoch: 33\tLoss: 0.527327\n",
      "Train Epoch: 34\tLoss: 0.517539\n",
      "Train Epoch: 35\tLoss: 0.514253\n",
      "Train Epoch: 36\tLoss: 0.523863\n",
      "Train Epoch: 37\tLoss: 0.550202\n",
      "Train Epoch: 38\tLoss: 0.607478\n",
      "Train Epoch: 39\tLoss: 0.606274\n",
      "Train Epoch: 40\tLoss: 0.597983\n",
      "Train Epoch: 41\tLoss: 0.558785\n",
      "Train Epoch: 42\tLoss: 0.511871\n",
      "Train Epoch: 43\tLoss: 0.489614\n",
      "Train Epoch: 44\tLoss: 0.462406\n",
      "Train Epoch: 45\tLoss: 0.448937\n",
      "Train Epoch: 46\tLoss: 0.435526\n",
      "Train Epoch: 47\tLoss: 0.427298\n",
      "Train Epoch: 48\tLoss: 0.419168\n",
      "Train Epoch: 49\tLoss: 0.413098\n",
      "Train Epoch: 50\tLoss: 0.407242\n",
      "Train Epoch: 51\tLoss: 0.402302\n",
      "Train Epoch: 52\tLoss: 0.397527\n",
      "Train Epoch: 53\tLoss: 0.393276\n",
      "Train Epoch: 54\tLoss: 0.389098\n",
      "Train Epoch: 55\tLoss: 0.385325\n",
      "Train Epoch: 56\tLoss: 0.381615\n",
      "Train Epoch: 57\tLoss: 0.378217\n",
      "Train Epoch: 58\tLoss: 0.374851\n",
      "Train Epoch: 59\tLoss: 0.371764\n",
      "Train Epoch: 60\tLoss: 0.368654\n",
      "Train Epoch: 61\tLoss: 0.365786\n",
      "Train Epoch: 62\tLoss: 0.362926\n",
      "Train Epoch: 63\tLoss: 0.360312\n",
      "Train Epoch: 64\tLoss: 0.357665\n",
      "Train Epoch: 65\tLoss: 0.355281\n",
      "Train Epoch: 66\tLoss: 0.352833\n",
      "Train Epoch: 67\tLoss: 0.350622\n",
      "Train Epoch: 68\tLoss: 0.348345\n",
      "Train Epoch: 69\tLoss: 0.346307\n",
      "Train Epoch: 70\tLoss: 0.344184\n",
      "Train Epoch: 71\tLoss: 0.342396\n",
      "Train Epoch: 72\tLoss: 0.340420\n",
      "Train Epoch: 73\tLoss: 0.338773\n",
      "Train Epoch: 74\tLoss: 0.336886\n",
      "Train Epoch: 75\tLoss: 0.335441\n",
      "Train Epoch: 76\tLoss: 0.333597\n",
      "Train Epoch: 77\tLoss: 0.332237\n",
      "Train Epoch: 78\tLoss: 0.330450\n",
      "Train Epoch: 79\tLoss: 0.329107\n",
      "Train Epoch: 80\tLoss: 0.327255\n",
      "Train Epoch: 81\tLoss: 0.325861\n",
      "Train Epoch: 82\tLoss: 0.323897\n",
      "Train Epoch: 83\tLoss: 0.322307\n",
      "Train Epoch: 84\tLoss: 0.320205\n",
      "Train Epoch: 85\tLoss: 0.318457\n",
      "Train Epoch: 86\tLoss: 0.316181\n",
      "Train Epoch: 87\tLoss: 0.314280\n",
      "Train Epoch: 88\tLoss: 0.311932\n",
      "Train Epoch: 89\tLoss: 0.309894\n",
      "Train Epoch: 90\tLoss: 0.307600\n",
      "Train Epoch: 91\tLoss: 0.305541\n",
      "Train Epoch: 92\tLoss: 0.303308\n",
      "Train Epoch: 93\tLoss: 0.301284\n",
      "Train Epoch: 94\tLoss: 0.299201\n",
      "Train Epoch: 95\tLoss: 0.297252\n",
      "Train Epoch: 96\tLoss: 0.295265\n",
      "Train Epoch: 97\tLoss: 0.293419\n",
      "Train Epoch: 98\tLoss: 0.291532\n",
      "Train Epoch: 99\tLoss: 0.289805\n",
      "Train Epoch: 100\tLoss: 0.288056\n",
      "Train Epoch: 101\tLoss: 0.286434\n",
      "Train Epoch: 102\tLoss: 0.284809\n",
      "Train Epoch: 103\tLoss: 0.283275\n",
      "Train Epoch: 104\tLoss: 0.281768\n",
      "Train Epoch: 105\tLoss: 0.280323\n",
      "Train Epoch: 106\tLoss: 0.278905\n",
      "Train Epoch: 107\tLoss: 0.277544\n",
      "Train Epoch: 108\tLoss: 0.276198\n",
      "Train Epoch: 109\tLoss: 0.274900\n",
      "Train Epoch: 110\tLoss: 0.273619\n",
      "Train Epoch: 111\tLoss: 0.272377\n",
      "Train Epoch: 112\tLoss: 0.271143\n",
      "Train Epoch: 113\tLoss: 0.269945\n",
      "Train Epoch: 114\tLoss: 0.268769\n",
      "Train Epoch: 115\tLoss: 0.267619\n",
      "Train Epoch: 116\tLoss: 0.266481\n",
      "Train Epoch: 117\tLoss: 0.265387\n",
      "Train Epoch: 118\tLoss: 0.264282\n",
      "Train Epoch: 119\tLoss: 0.263223\n",
      "Train Epoch: 120\tLoss: 0.262152\n",
      "Train Epoch: 121\tLoss: 0.261125\n",
      "Train Epoch: 122\tLoss: 0.260093\n",
      "Train Epoch: 123\tLoss: 0.259086\n",
      "Train Epoch: 124\tLoss: 0.258094\n",
      "Train Epoch: 125\tLoss: 0.257105\n",
      "Train Epoch: 126\tLoss: 0.256139\n",
      "Train Epoch: 127\tLoss: 0.255179\n",
      "Train Epoch: 128\tLoss: 0.254235\n",
      "Train Epoch: 129\tLoss: 0.253308\n",
      "Train Epoch: 130\tLoss: 0.252388\n",
      "Train Epoch: 131\tLoss: 0.251485\n",
      "Train Epoch: 132\tLoss: 0.250608\n",
      "Train Epoch: 133\tLoss: 0.249727\n",
      "Train Epoch: 134\tLoss: 0.248862\n",
      "Train Epoch: 135\tLoss: 0.248007\n",
      "Train Epoch: 136\tLoss: 0.247164\n",
      "Train Epoch: 137\tLoss: 0.246318\n",
      "Train Epoch: 138\tLoss: 0.245495\n",
      "Train Epoch: 139\tLoss: 0.244674\n",
      "Train Epoch: 140\tLoss: 0.243885\n",
      "Train Epoch: 141\tLoss: 0.243090\n",
      "Train Epoch: 142\tLoss: 0.242326\n",
      "Train Epoch: 143\tLoss: 0.241566\n",
      "Train Epoch: 144\tLoss: 0.240814\n",
      "Train Epoch: 145\tLoss: 0.240079\n",
      "Train Epoch: 146\tLoss: 0.239347\n",
      "Train Epoch: 147\tLoss: 0.238646\n",
      "Train Epoch: 148\tLoss: 0.237941\n",
      "Train Epoch: 149\tLoss: 0.237261\n",
      "Train Epoch: 150\tLoss: 0.236581\n",
      "Train Epoch: 151\tLoss: 0.235921\n",
      "Train Epoch: 152\tLoss: 0.235267\n",
      "Train Epoch: 153\tLoss: 0.234635\n",
      "Train Epoch: 154\tLoss: 0.234013\n",
      "Train Epoch: 155\tLoss: 0.233398\n",
      "Train Epoch: 156\tLoss: 0.232800\n",
      "Train Epoch: 157\tLoss: 0.232201\n",
      "Train Epoch: 158\tLoss: 0.231616\n",
      "Train Epoch: 159\tLoss: 0.231049\n",
      "Train Epoch: 160\tLoss: 0.230498\n",
      "Train Epoch: 161\tLoss: 0.229936\n",
      "Train Epoch: 162\tLoss: 0.229386\n",
      "Train Epoch: 163\tLoss: 0.228827\n",
      "Train Epoch: 164\tLoss: 0.228291\n",
      "Train Epoch: 165\tLoss: 0.227734\n",
      "Train Epoch: 166\tLoss: 0.227225\n",
      "Train Epoch: 167\tLoss: 0.226670\n",
      "Train Epoch: 168\tLoss: 0.226158\n",
      "Train Epoch: 169\tLoss: 0.225618\n",
      "Train Epoch: 170\tLoss: 0.225114\n",
      "Train Epoch: 171\tLoss: 0.224572\n",
      "Train Epoch: 172\tLoss: 0.224069\n",
      "Train Epoch: 173\tLoss: 0.223504\n",
      "Train Epoch: 174\tLoss: 0.223015\n",
      "Train Epoch: 175\tLoss: 0.222426\n",
      "Train Epoch: 176\tLoss: 0.221909\n",
      "Train Epoch: 177\tLoss: 0.221292\n",
      "Train Epoch: 178\tLoss: 0.220751\n",
      "Train Epoch: 179\tLoss: 0.220114\n",
      "Train Epoch: 180\tLoss: 0.219537\n",
      "Train Epoch: 181\tLoss: 0.218881\n",
      "Train Epoch: 182\tLoss: 0.218273\n",
      "Train Epoch: 183\tLoss: 0.217599\n",
      "Train Epoch: 184\tLoss: 0.216994\n",
      "Train Epoch: 185\tLoss: 0.216308\n",
      "Train Epoch: 186\tLoss: 0.215700\n",
      "Train Epoch: 187\tLoss: 0.215025\n",
      "Train Epoch: 188\tLoss: 0.214427\n",
      "Train Epoch: 189\tLoss: 0.213745\n",
      "Train Epoch: 190\tLoss: 0.213139\n",
      "Train Epoch: 191\tLoss: 0.212469\n",
      "Train Epoch: 192\tLoss: 0.211864\n",
      "Train Epoch: 193\tLoss: 0.211201\n",
      "Train Epoch: 194\tLoss: 0.210597\n",
      "Train Epoch: 195\tLoss: 0.209941\n",
      "Train Epoch: 196\tLoss: 0.209337\n",
      "Train Epoch: 197\tLoss: 0.208701\n",
      "Train Epoch: 198\tLoss: 0.208107\n",
      "Train Epoch: 199\tLoss: 0.207490\n",
      "Train Epoch: 200\tLoss: 0.206906\n",
      "Train Epoch: 201\tLoss: 0.206309\n",
      "Train Epoch: 202\tLoss: 0.205734\n",
      "Train Epoch: 203\tLoss: 0.205150\n",
      "Train Epoch: 204\tLoss: 0.204591\n",
      "Train Epoch: 205\tLoss: 0.204025\n",
      "Train Epoch: 206\tLoss: 0.203482\n",
      "Train Epoch: 207\tLoss: 0.202932\n",
      "Train Epoch: 208\tLoss: 0.202411\n",
      "Train Epoch: 209\tLoss: 0.201881\n",
      "Train Epoch: 210\tLoss: 0.201377\n",
      "Train Epoch: 211\tLoss: 0.200866\n",
      "Train Epoch: 212\tLoss: 0.200369\n",
      "Train Epoch: 213\tLoss: 0.199870\n",
      "Train Epoch: 214\tLoss: 0.199388\n",
      "Train Epoch: 215\tLoss: 0.198905\n",
      "Train Epoch: 216\tLoss: 0.198435\n",
      "Train Epoch: 217\tLoss: 0.197961\n",
      "Train Epoch: 218\tLoss: 0.197498\n",
      "Train Epoch: 219\tLoss: 0.197029\n",
      "Train Epoch: 220\tLoss: 0.196571\n",
      "Train Epoch: 221\tLoss: 0.196113\n",
      "Train Epoch: 222\tLoss: 0.195662\n",
      "Train Epoch: 223\tLoss: 0.195212\n",
      "Train Epoch: 224\tLoss: 0.194770\n",
      "Train Epoch: 225\tLoss: 0.194329\n",
      "Train Epoch: 226\tLoss: 0.193898\n",
      "Train Epoch: 227\tLoss: 0.193469\n",
      "Train Epoch: 228\tLoss: 0.193042\n",
      "Train Epoch: 229\tLoss: 0.192622\n",
      "Train Epoch: 230\tLoss: 0.192199\n",
      "Train Epoch: 231\tLoss: 0.191779\n",
      "Train Epoch: 232\tLoss: 0.191364\n",
      "Train Epoch: 233\tLoss: 0.190953\n",
      "Train Epoch: 234\tLoss: 0.190544\n",
      "Train Epoch: 235\tLoss: 0.190141\n",
      "Train Epoch: 236\tLoss: 0.189737\n",
      "Train Epoch: 237\tLoss: 0.189339\n",
      "Train Epoch: 238\tLoss: 0.188941\n",
      "Train Epoch: 239\tLoss: 0.188550\n",
      "Train Epoch: 240\tLoss: 0.188158\n",
      "Train Epoch: 241\tLoss: 0.187771\n",
      "Train Epoch: 242\tLoss: 0.187387\n",
      "Train Epoch: 243\tLoss: 0.187006\n",
      "Train Epoch: 244\tLoss: 0.186626\n",
      "Train Epoch: 245\tLoss: 0.186254\n",
      "Train Epoch: 246\tLoss: 0.185877\n",
      "Train Epoch: 247\tLoss: 0.185510\n",
      "Train Epoch: 248\tLoss: 0.185139\n",
      "Train Epoch: 249\tLoss: 0.184770\n",
      "Train Epoch: 250\tLoss: 0.184407\n",
      "Train Epoch: 251\tLoss: 0.184043\n",
      "Train Epoch: 252\tLoss: 0.183685\n",
      "Train Epoch: 253\tLoss: 0.183323\n",
      "Train Epoch: 254\tLoss: 0.182966\n",
      "Train Epoch: 255\tLoss: 0.182612\n",
      "Train Epoch: 256\tLoss: 0.182262\n",
      "Train Epoch: 257\tLoss: 0.181911\n",
      "Train Epoch: 258\tLoss: 0.181565\n",
      "Train Epoch: 259\tLoss: 0.181220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 260\tLoss: 0.180877\n",
      "Train Epoch: 261\tLoss: 0.180534\n",
      "Train Epoch: 262\tLoss: 0.180194\n",
      "Train Epoch: 263\tLoss: 0.179855\n",
      "Train Epoch: 264\tLoss: 0.179518\n",
      "Train Epoch: 265\tLoss: 0.179183\n",
      "Train Epoch: 266\tLoss: 0.178850\n",
      "Train Epoch: 267\tLoss: 0.178519\n",
      "Train Epoch: 268\tLoss: 0.178188\n",
      "Train Epoch: 269\tLoss: 0.177860\n",
      "Train Epoch: 270\tLoss: 0.177530\n",
      "Train Epoch: 271\tLoss: 0.177205\n",
      "Train Epoch: 272\tLoss: 0.176881\n",
      "Train Epoch: 273\tLoss: 0.176558\n",
      "Train Epoch: 274\tLoss: 0.176237\n",
      "Train Epoch: 275\tLoss: 0.175916\n",
      "Train Epoch: 276\tLoss: 0.175601\n",
      "Train Epoch: 277\tLoss: 0.175283\n",
      "Train Epoch: 278\tLoss: 0.174971\n",
      "Train Epoch: 279\tLoss: 0.174657\n",
      "Train Epoch: 280\tLoss: 0.174348\n",
      "Train Epoch: 281\tLoss: 0.174036\n",
      "Train Epoch: 282\tLoss: 0.173733\n",
      "Train Epoch: 283\tLoss: 0.173424\n",
      "Train Epoch: 284\tLoss: 0.173122\n",
      "Train Epoch: 285\tLoss: 0.172819\n",
      "Train Epoch: 286\tLoss: 0.172519\n",
      "Train Epoch: 287\tLoss: 0.172220\n",
      "Train Epoch: 288\tLoss: 0.171921\n",
      "Train Epoch: 289\tLoss: 0.171624\n",
      "Train Epoch: 290\tLoss: 0.171330\n",
      "Train Epoch: 291\tLoss: 0.171035\n",
      "Train Epoch: 292\tLoss: 0.170743\n",
      "Train Epoch: 293\tLoss: 0.170454\n",
      "Train Epoch: 294\tLoss: 0.170164\n",
      "Train Epoch: 295\tLoss: 0.169876\n",
      "Train Epoch: 296\tLoss: 0.169592\n",
      "Train Epoch: 297\tLoss: 0.169307\n",
      "Train Epoch: 298\tLoss: 0.169026\n",
      "Train Epoch: 299\tLoss: 0.168746\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    train(model, X_train, y_train, optimizer, criterion, epoch, 'print')\n",
    "#    test(model, X_test, y_test, criterion, 'print')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1753\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1753)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, X_test, y_test, criterion, 'print')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(300, 10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "min_error = 999\n",
    "epoch = count = 0\n",
    "train_loss_vec = []\n",
    "test_loss_vec = []\n",
    "\n",
    "while (epoch < 100 and count < 30):\n",
    "    train_loss = train(model, X_train, y_train, optimizer, criterion, epoch, '')\n",
    "    test_loss = test(model, X_test, y_test, criterion)\n",
    "    train_loss_vec.append(train_loss)\n",
    "    test_loss_vec.append(test_loss)\n",
    "    epoch += 1\n",
    "    if test_loss >= min_error:\n",
    "        count += 1\n",
    "    else:\n",
    "        min_error = test_loss\n",
    "        \n",
    "test(model, X_test, y_test, criterion, 'print')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGt9JREFUeJzt3X2QHPV95/H3t3tm9kkSktDyKCGBEOZJtgVrITCxr+ScDZiznQuJSV1ic3EdcXKXEFecBOxcOU7l6mzK5cOuoqhw2CRxOOyAHeM4lDEH2MlV2ZJXEpgH8SAehAABqwckoZ3deejv/fHr3Z3R4wg0mu6Zz6uqmeme2dW3q8VnfvrOr7vN3RERkfyIOl2AiIgcGQW3iEjOKLhFRHJGwS0ikjMKbhGRnFFwi4jkjIJbRCRnFNwiIjmj4BYRyZlCO37pggULfMmSJe341SIiXWndunXb3H24lfe2JbiXLFnC6OhoO361iEhXMrPNrb5XrRIRkZxRcIuI5IyCW0QkZxTcIiI5o+AWEckZBbeISM4ouEVEciYzwV2twpe/DD/+cacrERHJtswEd6EAN94Id93V6UpERLItM8FtBitWwIYN6YYHH4Snn+5oTSIiWZSZ4IYQ3I8+GtomXHMN3HBDp0sSEcmczAV3pQIbNwJ79oCudyIisp/MBTek7ZJyGV58EbZt62hNIiJZk6ngPussGBiADesdJifDxvXrO1uUiEjGZCq44xje+U7YsD6Z2bhuXecKEhHJoEwFN4R2ycOPGAkWNii4RUSaZDK4d++JeJ7TwxxBBbeISJNMBjfABlbA8uXwwguwfXtHaxIRyZLMBffy5RDHzsO8Gy69NGzUF5QiItMyF9z9/XDO4nIYcU8Ft9olIiLTMhfcACuW7grBffLJcMYZCm4RkQbZDO7FO9nKKbw2PhsuvFDBLSLSIJvBvXAMgA2b54fgfv552Lmzw1WJiGRDJoP73SduBWDDs3NCcIO+oBQRSWUyuOfaLk7lJZ7e0j8zP1DtEhERIKPBTbnMLN6kXC3A8cfDkiUNF+oWEeltLQW3mX3GzB43s8fM7E4z629rVeUy/UyE4AY44QT1uEVEUocNbjM7FfgjYMTdzwdi4Oq2VlUuM0CZ8mRa3sBAuMyriIi03CopAANmVgAGgVfaVxIhuKNJJibSC00puEVEph02uN39ZeArwIvAVmCXu+93L3Yzu9bMRs1sdGxs7O1VNT5Of1ydyWoFt4jItFZaJfOAjwKnA6cAQ2b22/u+z91vdfcRdx8ZHh5+e1WVyww0Bnd/P0xMvL3fKSLSJVpplfwq8Ly7j7l7FfgecElbqyqXGShqxC0iciCtBPeLwCozGzQzAz4AbGxrVeUyA8XazCBbwS0iMq2VHvca4G5gPfBo+jO3trWq8XH6i4lG3CIiB1Bo5U3u/gXgC22uZUa5zECpTnlXuj4V3O7hrjgiIj0ss2dODvQlTEyErGZgIGyvVDpalohIFmQ2uPv7HIDJScKsknS7iEivy2Zwj48z0B+Cu1xmZsSt4BYRyWhwl8vNWa3gFhGZlt3gHgxfQk5MoOAWEWmQ2eDuH7CppwpuEZEG2QvuWg2qVQaGQmnlMjNfTuq0dxGRDAZ3OqpuCm6NuEVEpmU3uGeF0tTjFhFpltng7p9VnFlVcIuITMtscA/MLsysKrhFRKZlL7jHxwEYmKMRt4jIgWQvuKdaJbNDcE9MoFklIiINMhvcA3P7ZlY14hYRmZaP4C6VwuVcFdwiIhkM7rTHXZrTj1naHTHTzRRERFLZC+40nG1wgP7+hqxWcIuIABkObgYHm7NawS0iAmQ5uAcGmrO6v1+zSkREyHhwN2W1RtwiIkAWg3t8HKIIikW1SkREDiB7wV0uw+AgmCm4RUQOIJvBnZ5wo+AWEdlfpoO7qcfdNDdQRKR3ZS+4x8cPPuLWrBIRkQwGt1olIiKHlM3gHhwE0HRAEZEDyGZwa8QtInJQ2QvuQ/W4y2Vw71xtIiIZkL3gPsCI252ZmylUKp2rTUQkA7IZ3A097iSBWg3dTEFEJJXN4G4YcU9tUnCLiAQKbhGRnMlWcLvv9+UkKLhFRBplK7ir1dDUbuhxwz53eldwi0iPy1ZwN1yLu+GhecSt095FpMe1FNxmNtfM7jazJ81so5ld3JZqWglujbhFpMcVWnzf14AfuftVZlYCBttSTXqH98arA0I6yD5OwS0iAi0Et5kdB7wPuAbA3StAe86COdSI+yQFt4gItNYqOR0YA243sw1mdpuZDbWlmoY7vINaJSIiB9JKcBeAC4Bb3H0FsBe4ft83mdm1ZjZqZqNjY2NvrZpDjbg1q0REBGgtuF8CXnL3Nen63YQgb+Lut7r7iLuPDA8Pv7VqDtXj1qwSERGgheB291eBLWb2jnTTB4An2lKNZpWIiBxWq7NK/hC4I51R8hzwn9tSzaF63KUSmCm4RaTntRTc7v4wMNLmWvYbcTe1tc10MwURETJ+5mQUhYG27vQuIjIjW8G9z5eTU091+zIRkRnZCu59RtxTT5uCW7NKRKTHZS+4i0UozLTedad3EZFm2QvuhtE2qFUiIrKvbAV3w00Upii4RUSaZSu4G24UPKUpqzWrREQkg8G9z4hbPW4RkWaZD27NKhERaZa/4NaIW0R6XLaC+wBfTja1tRXcIiIZC+6DfDmpU95FRGZkL7hbaZW4H/vaREQyIn/BDVBpzy0vRUTyIFvBfZAed7UK9Tq6mYKICFkL7oP0uGGf25cpuEWkh7V6B5xj4/vfh0WLmjY1ZvWQgltEJGPB/cEP7rep6S44utO7iEjGWiUHoFaJiEiz3AR3053eddq7iPSwfAa3Rtwi0sMyH9xNbW0Ft4hI9oO7qTuiLydFRPIT3Bpxi4gEmQ9utUpERJplPrg1q0REpFluglvzuEVEgtwEd7kMlEpgpuAWkZ6W+eBu6nGb6WYKItLzMh/cxSLEse70LiIyJfPBDbphsIhIo3wGt2aViEgPy0Vw607vIiIzchHcTYNsBbeI9LhcBPfgIOzdm65oVomI9LhcBPfcufDGG+nKccfB7t0drUdEpJNaDm4zi81sg5n9sJ0FHcj8+bBzZ8PKjh3HugQRkcw4khH3dcDGdhVyKPPmNWR104qISO9pKbjNbCHwYeC29pZzYE2D7Pnz4c03oVLpRCkiIh3X6oj7JuDPgKSNtRzU/PkwOZl+Jzl/ftg43TsREekthw1uM7sSeN3d1x3mfdea2aiZjY6NjR21AiF0RyAddU8Ft9olItKjWhlxvxf4iJm9AHwbWG1m/7Dvm9z9VncfcfeR4eHho1pkU1ZrxC0iPe6wwe3uN7j7QndfAlwNPOjuv932yho0ZbVG3CLS43Ixj1utEhGRGYUjebO7/wT4SVsqOYQDtkoU3CLSo3Ix4m5qlRx3XLihgoJbRHpULoJ79uxwM4UdO4Ao0kk4ItLTchHcZiGrpyeSKLhFpIflIrjhAGdPKrhFpEflJribBtlNV50SEektuQluXSFQRCTIVXCrVSIikqPgPmCrJOnINa9ERDoqN8E9fz7s2gX1erriHjaIiPSYXAX3dFbr7EkR6WG5CW5dr0REJMhNcDed9t6U4iIivSV3wa0Rt4j0utwE9wFbJToJR0R6UG6CW60SEZEgN8HdlNWlEsyapeAWkZ6Um+AulWBoSGdPiojkJrhB1ysREYGcBfd+p70ruEWkB+UquDXiFhHJYXBPZ7XugiMiPSpXwX3AKwS6d7QmEZFjLVfBvV+rpFKB8fGO1iQicqzlLrgnJqBcRqe9i0jPylVw6wqBIiI5C+6m094V3CLSo3IZ3Bpxi0gvy1Vwq1UiIpKz4FarREQkp8G9YwcwMBCuPKVrcotIj8lVcM+eDXGcBreZTnsXkZ6Uq+A2C31uXa9ERHpZroIb9slqBbeI9KDcBfd+1yvZvr2j9YiIHGu5C+5Fi+DZZ9OVpUvh6aehWu1oTSIix1LugntkBJ57Lh1or1oVLl7yy192uiwRkWMmd8G9cmV4/MUvgIsuCis//3nH6hEROdYOG9xmtsjMHjKzJ8zscTO77lgUdjAXXhhml6xdC5x2Gpx0EqxZ08mSRESOqUIL76kBf+Lu681sNrDOzO539yfaXNsBzZkD55yTBrdZGHUruEWkhxx2xO3uW919ffp8D7AROLXdhR3KypUhuN0Jfe6nn9a0QBHpGUfU4zazJcAKYL8hrplda2ajZjY6NjZ2dKo7iJUrYWwMNm9mps+9dm1b/0wRkaxoObjNbBbwXeCP3X33vq+7+63uPuLuI8PDw0ezxv1MfUG5di1hmkkU6QtKEekZLQW3mRUJoX2Hu3+vvSUd3vLl0NeXBvfs2XDeeepzi0jPaGVWiQHfADa6+1fbX9LhlUqwYkVDd2TVqhDcuuO7iPSAVkbc7wV+B1htZg+nyxVtruuwVq6EdeugViP0uXfuhGee6XRZIiJt18qskv/n7ubu73T3d6fLvceiuENZuRLGx+GJJwgjblCfW0R6Qu7OnJzS9AXl2WeHXrf63CLSA3Ib3GeeCXPnpsEdxyHJf/azTpclItJ2uQ1us5DVDz0ESQJ86EOwYYPaJSLS9XIb3ADXXAObNsE//iPw+78PJ5wAn/98p8sSEWmrXAf3xz8O558PX/gC1Ppnwec+Bw8+CA880OnSRETaJtfBHUXwV38VLlVyxx3A7/0eLFwYRt2a0y0iXSrXwQ3wsY/BBRfAF78Ilag/DL/XrIF//udOlyYi0ha5D24z+Ou/huefh9tvBz75SVi2LLRNKpVOlycictTlPrgBLrsMLr4Y/vIvYeyNInzlK/D44/Cnf9rp0kREjrquCG4zuPnmcEnuT3wCkis/AtddB1//Otx9d6fLExE5qroiuCFcdOqmm+BHP4IbbyT8Z9Uq+N3f1TVMRKSrdE1wA3z602GK4F/8BfzbmhJ85ztQLMJVV8GuXZ0uT0TkqOiq4DaDW2+F008PAf58/TS4885wJarLLoPd+93/QUQkd7oquCHcTPif/gkmJ2H1athyzgfhrrtgdDScFq/wFpGc67rghnA25Y9/HL6sXL0atl70sXBe/OhoGHlv397pEkVE3rKuDG6ACy8MX1Ru3RrC+7l3/Vroea9bF65O9dhjnS5RROQt6drghjC3+9574dVX4T3vgftn/0f46U/DHRguvhjuuafTJYqIHLGuDm6A970vdEhOPTV0Sb7801Uka0fhnHPC+fJ/8AeacSIiudL1wQ2wdGm4x8Jv/AZcfz2s/p1Tefb2f4XPfAb+5m/CXeI1+haRnOiJ4AYYGgozA2+7Ldxv4Z0r+7nptK9S+bc1cPzxYfT9K78SGuO6sqCIZFjPBDeEed6f+lT4XvL97w8D7iVXjfA/fn092/7n/4YXXoDLLw8N8Ztvhpdf7nTJIiL7MW/D6HJkZMRHR0eP+u89mtzhvvvCafL33Qd9ffAfPpzwWyc+yBUPfpb+px4Jb7zoohDky5aFnksUkbyxm5c315g1sY15E1vDvMO+vtBIX7gQLr0Ulizp6P6JSL6Y2Tp3H2npvb0a3I2eeAJuuSXMFhwbg1mzYMnJEyyovcr8Xc9T2L2DpJZQo8BmFvMU72CcIQBO4WXOLz3NR6Mf8l8mvk6RWgjxG26AP/9z6O/v8N6JSB4ouN+iWi3c+eyee+CVV8J5Otu3Q5I4UVInqk2y8IQK55yVcNbZEbvrQzz+TJH1643HHoOzzky48Q+38JGffw678/+EW9HfdBNccUXo04iIHISC+xhzh3/5l3D57yefhEsugf9+5QY+9M2PY5uegeXL4bOfhauvhlKp0+WKSAYdSXD31JeT7WIGV14Jjz4aWi5btsDln1vBe+Y8ybc//RPKtWK4M8/ixaGFosvMisjboBF3G1Qq8K1vwZe+BJs2wezZzq+tfJlf3/23vHf0axzv28K1wi+5JJx+PzISLmkY6XNUpFepVZIR9Xo4w/6OO+C73505QfOsBdt5D7/grJ1rWVbfyDKeYenAVuaddwqce26YkbJ4MZx2GgwPw4IFYenra/0Pfu01qFSo1iO2bC0wx3exYOKlcPGWwcFw5uiyZWrdiGSEgjuDJibCzed/9rOwbNgQWiqN5hb2cBpbmFsbYzZ7mMNuFrCNYcaYx06qxUHK/fOZ7JtDMarRzyQFarxUO4lnqkt4rrqQes3pq+2lSJXXOYEtLCIhBuBkXuFdPMI7eIrFbGZxtIXli3Zx5tkF7Myl4bKKq1eHQNeXqSLHlII7J8plePbZ0E557rmwbNkCu3cl7N5WZdcbCdt2xuwaP/SouD+aZOnQaywd3EqpP6LSN4vJwhAL5lQ5Y3g3S+bv4Y1kDo+8fjKPbJ7Lps0F9pbj6Z9fXHqFf+/38/7q/SznUc4+ZQ9977sofKm6fHm4JMDixRDHh6hCRN4OBXeXqVRg587Q1RgcDI/1ehjFT07CvHlH1h53D+cMvfACrF0L998PDzzg7N4dRtmx1Vkav8Cy2kbOZBNn8BwnxtsZPrnA8GkDzD+ln3mLZjFwyjzs+Pkwf34oYs6csMyeHSbD9/dr5C7SIgW3HLFaDZ56Ch5/PFwSYONGeObJOpuepWl03qjEJLPZwyzeZDZ7GGLv9DLIOANMMFisMlCsMdBXZ6CUMNCX0NcP/X0h1/sHjP4Bo28wpm8gCo+DMX1DhaalNFSkNFSkOFTCpn64r29mKZWaHwsFfWhIrhxJcBfaXYzkQ6EQOiLnnQe/+ZtTW2PcYdu2cEbp66+Hx507YecOZ+erzps7SuzZMZs9bwyyd6+zdy9sH48oT0aUKzHjlQLlSpHyeBE/SrNPS0xSorLP8iYldlCkSolKeLQaxahOKapRjOsUo4RivM9ScAqxh8eCUyxAseAUi+E+04UiFApGoWhhW8kolqBQjCiU0qVoM89LEXEpptAXz2ybet5fIC6Gx0JfeE9cion7i+F5X4GoVAgHY99FM46kgYJbDsksTGwZHg4TXhpeAfrT5fDcQ8tnYiIs5XJo8zQ+r1RgspwwubfG5JtVJvZUqZTrVMZrVMp1JsfrVCYSJicSJstOdTKhWnEmJ6FahUqlxGSlj2oNqjWjUjUmahGVekS1FlFNIqr1iOpkHJ4nMdWkQM0jql6g6oWj9uHyVhkJMXVi6hSoEVNOH8N6hBNbndgSYhIKVgvPLWyPDApWJ44SCpYQRwmRQWROHDmFKGyLzYmi8HkQRwlxBIU4PEYNSxyHn4tjI46cKIYoMuKY6SWKIIoNm9peILw/BouMKDaiON1WmFqfWeICxIUorBcMi8LzuBgRF8LPWByF31VItxWj6Z+3OCIqRE2vWRw1b09/lxViLAqPcXHmZ6LYMAt/38N+z+wbzGzPyuengluOCbOZrsZxxx3qnRFQSpdjL0nCh0C1GtpHtdrM8+ntk3VqEzWq41XqlXpYn6xTnaiH9UoStjU81qsJtao3Pa9WnHotLLVq+rzu1KrhO4x6zanVwvNaPdSQJFCvW3g9fV5LjHrdwmsJ1JOIWhJRSwrUEiNxo54Y9ZqF1zyi7hHukLhR85h6uq3mMU76Mx5TJwofIx6REJY6cfq8N7+sjqlh+PQSmYcPW0s4qW8nT42f1vYaFNwiDaJo5gPm4OJ0aXFefZdyh3o1wWt1kmpY6pU69Wqd2mSC1xOSWhJeq3v6Wtjm9fABltSdejVp2p7UE5Jauj39YPPEp39f+ICDpJ7gdSeZWhKa3580bE8/CKe2e+LUE0jq4bUkAXcPvy8hfNDVwz5O/650e5JA4uBJeL1x+9AQQEaC28wuA75G+Nt6m7t/qa1ViUjmmUGhFEEpAoqdLqenHLZjY2YxcDNwOXAu8Ftmdu6hf0pERNqllVb7SmCTuz/n7hXg28BH21uWiIgcTCvBfSrQeHL2S+k2ERHpgKM2ucXMrjWzUTMbHRsbO1q/VkRE9tFKcL8MLGpYX5hua+Lut7r7iLuPDA8PH636RERkH60E9y+AZWZ2upmVgKuBH7S3LBEROZjDTgd095qZ/TfgPsJ0wG+6++Ntr0xERA6opXnc7n4vcG+baxERkRa05eqAZjYGbH6LP74A2HYUy8mDXtxn6M397sV9ht7c7yPd58Xu3tIXhG0J7rfDzEZbvbRht+jFfYbe3O9e3Gfozf1u5z5n5FpXIiLSKgW3iEjOZDG4b+10AR3Qi/sMvbnfvbjP0Jv73bZ9zlyPW0REDi2LI24RETmEzAS3mV1mZk+Z2SYzu77T9bSLmS0ys4fM7Akze9zMrku3zzez+83smfRxXqdrPdrMLDazDWb2w3T9dDNbkx7z76Rn5nYVM5trZneb2ZNmttHMLu72Y21mn0n/bj9mZneaWX83Hmsz+6aZvW5mjzVsO+CxteDr6f7/0swueDt/diaCu8eu+V0D/sTdzwVWAf813dfrgQfcfRnwQLreba4DNjasfxn4X+5+JrAT+FRHqmqvrwE/cvezgXcR9r9rj7WZnQr8ETDi7ucTzra+mu481n8LXLbPtoMd28uBZelyLXDL2/mDMxHc9NA1v919q7uvT5/vIfyPfCphf/8ufdvfAR/rTIXtYWYLgQ8Dt6XrBqwG7k7f0o37fBzwPuAbAO5ecfc36PJjTTgje8DMCsAgsJUuPNbu/q/Ajn02H+zYfhT4ew9+Dsw1s5Pf6p+dleDuyWt+m9kSYAWwBjjR3bemL70KnNihstrlJuDPgCRdPx54w91r6Xo3HvPTgTHg9rRFdJuZDdHFx9rdXwa+ArxICOxdwDq6/1hPOdixPaoZl5Xg7jlmNgv4LvDH7r678TUPU326ZrqPmV0JvO7u6zpdyzFWAC4AbnH3FcBe9mmLdOGxnkcYXZ4OnAIMsX87oSe089hmJbhbuuZ3tzCzIiG073D376WbX5v6p1P6+Hqn6muD9wIfMbMXCG2w1YTe79z0n9PQncf8JeAld1+Trt9NCPJuPta/Cjzv7mPuXgW+Rzj+3X6spxzs2B7VjMtKcPfMNb/T3u43gI3u/tWGl34AfDJ9/kngnmNdW7u4+w3uvtDdlxCO7YPu/p+Ah4Cr0rd11T4DuPurwBYze0e66QPAE3TxsSa0SFaZ2WD6d31qn7v6WDc42LH9AfCJdHbJKmBXQ0vlyLl7JhbgCuBp4Fng852up437eSnhn0+/BB5OlysIPd8HgGeA/wvM73Stbdr/fwf8MH1+BrAW2ATcBfR1ur427O+7gdH0eH8fmNftxxr4IvAk8BjwLaCvG481cCehj18l/OvqUwc7toARZs49CzxKmHXzlv9snTkpIpIzWWmViIhIixTcIiI5o+AWEckZBbeISM4ouEVEckbBLSKSMwpuEZGcUXCLiOTM/wc+m2CuUBMaJwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_vec, \"r\")\n",
    "plt.hold = True\n",
    "plt.plot(test_loss_vec, \"b\")\n",
    "plt.hold = False\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
